# 反爬虫

服务器反爬虫的原因:

```
	占总PV较高,浪费资源

​	资源被批量抓走,丧失竞争力

​	法律灰色地带
```



服务器常反什么样的爬虫:

```
	应届毕业生

​	创业小公司

​	写错了,忘记停止

​	商业对手

​	搜索引擎
```



反爬虫的三个方向:

```
	基于身份识别进行反爬虫

​	基于爬虫行为进行反爬虫

​	基于数据加密进行反爬虫

```

常见基于身份识别进行的反爬虫:

```
headers
	ua
	referer
	cookies
请求参数
	从html文件中提取
	发送请求获取数据
	通过js生成
	通过验证码
```

常见基于爬虫行为进行反爬虫

```

基于请求频率或总请求数量
	ip/账号总请求数量
	ip/账号请求的时间间隔
	ip/账号请求次数限制
根据爬虫行为
	通过js实现跳转
	通过蜜罐获取爬虫ip
		style = display:none
	通过假数据反爬虫 
	阻塞任务队列
	阻塞网络IO
	运维平台综合审计

```

常见基于数据加密进行反爬虫

```
对响应中含有的数据进行特殊化处理
    通过自定义字体来反爬 下图来自猫眼电影电脑版
    通过css来反爬 下图来自猫眼去哪儿电脑版
    通过js动态生成数据进行反爬
    通过数据图片化反爬
    通过编码格式进行反爬
```



图像验证码

```
图像识别指令:trsseract 文件名 result
```

打码平台

```
1,云打码
2,极验验证码
```



常见的验证码种类

```
1,url不变,验证码不变
2,url不变,验证码变化
```

js-解析

```
1,定位js文件
	通过initiator定位到js文件
	通过search搜索关键字定位到js文件
	通过元素绑定的事件监听函数定位到js文件
2,分析js代码,掌握加密步骤
3,模拟加密步骤,使用python的方法重现
	通过第三方js加载模块直接加载js运行  js2py  pyv8
	纯python实现

地址去重
	url
	url_hash
	布隆过滤器
文本内容去重
	simhash进行海量文本去重
	编辑距离
```

